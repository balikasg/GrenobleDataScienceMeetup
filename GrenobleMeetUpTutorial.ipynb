{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grenoble Data Science Meet-up\n",
    "## An (intermediate) tutorial on (flat) text classification using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goals of the tutorial are to investigate the following:\n",
    "- Text loading, cleaning and encoding issues\n",
    "- Text vectorization using either counts or a hashing function + weighting schemes\n",
    "- Validation using hold out or k-fold cross validation\n",
    "- Performance evaluation using several families of classifiers (trees, svms, logistic regression, naive bayes)\n",
    "- Grid search to fine tune the above systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading.\n",
    "We live in a multi-lingual world. Unicode is our tool to handle languages/symbols etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the data\n",
    "raw_data = codecs.open('/home/balikasg/wikipediaData/data.meeptup.txt', 'r', encoding='utf8').read().splitlines() #Use codecs for handling noo-ASCII characters etc..\n",
    "labels = codecs.open('/home/balikasg/wikipediaData/labels.meeptup.txt', 'r', encoding='utf8').read().splitlines() #Here codecs is not necessary\n",
    "labels = [int(x.split(';')[2]) for x in labels] # From the labels, take only the leaf class, i.e., flat approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis\n",
    "We calculate and plot some of the aspects of our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 2825\n",
      "Average length of docs.: 95.105840708\n",
      "Different classes: 170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x58e96d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEZCAYAAACJjGL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMDOzuv4/kW4PRYbWX70AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac5cd21850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print \"Number of Documents:\", len(raw_data)\n",
    "print \"Average length of docs.:\", sum([len(x.split()) for x in raw_data])/float(len(raw_data))\n",
    "print \"Different classes:\", len(set(labels))\n",
    "\n",
    "# print \"Instances per class:\", Counter(labels)\n",
    "plt.hist(Counter(labels).values(), bins=np.arange(0, 215, 10), color='r', alpha=0.4)\n",
    "plt.grid()\n",
    "plt.title(\"Category system description: instances/class\")\n",
    "plt.xlabel(\"Train Instances\")\n",
    "plt.ylabel(\"Number of Classes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "Given text spans to be classified, the goals of the the step are the following:\n",
    "+ load the data,\n",
    "+ clean and preprocess them,\n",
    "+ tokenize them, and\n",
    "+ generate a vocabulary of n-grams and output the sparse vector matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string: I want to learn text classification with Python.\n",
      "Preprocess: i want to learn text classification with python.\n",
      "Tokenizer: ['want', 'to', 'learn', 'text', 'classification', 'with', 'Python']\n",
      "Analyzer: [u'want', u'to', u'learn', u'text', u'classification', u'with', u'python']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, HashingVectorizer, TfidfVectorizer\n",
    "\n",
    "# Define an example string to demnostrate the different steps of vectorization\n",
    "string = \"I want to learn text classification with Python.\"\n",
    "\n",
    "my_vec = CountVectorizer(ngram_range=(1,1)) #http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "print \"Original string:\", string\n",
    "print \"Preprocess:\", my_vec.build_preprocessor()(string)\n",
    "print \"Tokenizer:\", my_vec.build_tokenizer()(string)\n",
    "print \"Analyzer:\", my_vec.build_analyzer()(string)\n",
    "#Hint: why \"I\" does not appear? (token_pattern='(?u)\\b\\w\\w+\\b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and transformation\n",
    "The goal here it to select the most prominent features and/or apply a weighting scheme that will put emphasis on the some of them, just using the frequencies of their occurrence in the corpus. \n",
    "+ max_df = 1\n",
    "+ min_df = 1\n",
    "+ max_features = None\n",
    "\n",
    "The above-meantioned are hyper-parameters to be tuned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import  cross_validation, preprocessing\n",
    "import scipy.sparse as sp\n",
    "\n",
    "#Split the raw data in train/test. Use test *only* for testing. We will use this in the next cell.\n",
    "x_train_raw, x_test_raw, y_train, y_test = cross_validation.train_test_split(raw_data, labels, train_size=0.75,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "At this point the data have been projected to a vector space (i.e., each instance is a vector). This is a suitable data representation, that can be consequently fed in learning algorithm. Before that though, split..\n",
    "\n",
    "Machine learning algorithms must be evaluated on *unseen* data, that is data not belonging to the train data. The most straighforward approach is to split the data on train/test parts, and learn/evaluate the algorithm on the respective part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19228\n"
     ]
    }
   ],
   "source": [
    "#We will evaluate several representations. Hence, we make a dictionary that will keep the train/test data for each representation\n",
    "my_representations = list()\n",
    "for name, vectorizer in zip(['tf', 'hashing', 'tfidf', ],[CountVectorizer(ngram_range=(1,1)), HashingVectorizer(n_features=10000, non_negative=True), TfidfVectorizer()]):\n",
    "    vectorizer.fit(x_train_raw)\n",
    "    my_representations.append({\"name\":name, \"x_train\":vectorizer.transform(x_train_raw), \"x_test\":vectorizer.transform(x_test_raw)})\n",
    "    if name == 'tf':\n",
    "        print len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn offers access to a plethora of classifiers with the same API calls. In short, one must call the \"fit\" methods to learn the model's parameters and \"predict\" to get the predictions for data instances. Here is a non-exhaustive list of classifiers we will benchmark for our multi-class problem.\n",
    "+ Naive bayes \n",
    "+ Logistic Regression\n",
    "+ Support Vector Machines with linear kernel\n",
    "+ Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRepresentation: tf\n",
      "LR:\tAccuracy: 0.634\tF1 macro: 0.353\n",
      "SVM:\tAccuracy: 0.651\tF1 macro: 0.390\n",
      "5-NN:\tAccuracy: 0.471\tF1 macro: 0.233\n",
      "Rochio:\tAccuracy: 0.330\tF1 macro: 0.196\n",
      "N.B.:\tAccuracy: 0.390\tF1 macro: 0.113\n",
      "----------------\n",
      "\tRepresentation: hashing\n",
      "LR:\tAccuracy: 0.463\tF1 macro: 0.170\n",
      "SVM:\tAccuracy: 0.644\tF1 macro: 0.345\n",
      "5-NN:\tAccuracy: 0.516\tF1 macro: 0.257\n",
      "Rochio:\tAccuracy: 0.516\tF1 macro: 0.320\n",
      "N.B.:\tAccuracy: 0.242\tF1 macro: 0.027\n",
      "----------------\n",
      "\tRepresentation: tfidf\n",
      "LR:\tAccuracy: 0.515\tF1 macro: 0.202\n",
      "SVM:\tAccuracy: 0.676\tF1 macro: 0.457\n",
      "5-NN:\tAccuracy: 0.595\tF1 macro: 0.343\n",
      "Rochio:\tAccuracy: 0.628\tF1 macro: 0.394\n",
      "N.B.:\tAccuracy: 0.303\tF1 macro: 0.054\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balikasg/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/balikasg/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:960: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes, linear_model, svm, ensemble, neighbors, metrics\n",
    "\n",
    "# Set hyper-parameters, for controlling algorithm\n",
    "learners = [{\"name\":\"LR\", \"model\":linear_model.LogisticRegression(C=1)}, \n",
    "            {\"name\":\"SVM\", \"model\":svm.LinearSVC(C=1)}, \n",
    "            {\"name\":\"5-NN\", \"model\":neighbors.KNeighborsClassifier(n_neighbors=5)}, \n",
    "            {\"name\":\"Rochio\", \"model\":neighbors.NearestCentroid()}, \n",
    "            {\"name\":\"N.B.\", \"model\":naive_bayes.MultinomialNB(alpha=1)}]\n",
    "\n",
    "# Loop and test the performance of each of the above learners\n",
    "for representation in my_representations:\n",
    "    print \"\\tRepresentation:\", representation[\"name\"]\n",
    "    for learner in learners:\n",
    "        learner['model'].fit(representation[\"x_train\"], y_train)\n",
    "        preds = learner['model'].predict(representation[\"x_test\"])\n",
    "        print \"%s:\\tAccuracy: %0.3f\\tF1 macro: %0.3f\"%(learner['name'], metrics.accuracy_score(y_test, preds), metrics.f1_score(y_test, preds, average='macro')) \n",
    "    print \"----------------\"\n",
    "\n",
    "    \n",
    "# Maybe: Make a comment on performance evaluation using cv    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing with GridSearch\n",
    "Learning algorithms, vectorization and weighting schemes ect. usually come with hyper-parameters i.e., parameters with default values that have to be tuned in order to obtain optimal performance. k-fold cross validation in conjunction with grid search is probably the most common way of tuning such parameters. Note, that is can become very cpu/memory expensive for large problems, that is problems with many features or many instances or both.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balikasg/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:417: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVM on accuracy (C=10.00): 0.700141442716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balikasg/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:370: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVM on f1_macro (C=10.00): 0.487716569715\n"
     ]
    }
   ],
   "source": [
    "from sklearn import grid_search #http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html\n",
    "\n",
    "# We will tune the C value of SVMs to optimize first accuracy and the f1_macro\n",
    "for eval_meas in [\"accuracy\", \"f1_macro\"]:\n",
    "    clf = grid_search.GridSearchCV(svm.LinearSVC(), param_grid={\"C\":[0.01, 0.1, 1, 10, 100]}, n_jobs=3, scoring=eval_meas, refit=True, cv=5)\n",
    "    clf.fit(my_representations[2][\"x_train\"], y_train) # Note that GridSearchCV is itself an estimator\n",
    "    print \"Tuned SVM on %s (C=%0.2f):\"%(eval_meas, clf.best_params_['C']), clf.score(my_representations[2][\"x_test\"], y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations (cont.)\n",
    "There are several feature transformations and weighting schemes proposed. Inspired by the presentation on our cDiscount participation, we demonstrate here the a_power tranformation on the tf-idf scheme with SVMs, that performed the best above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a new tranformation: element-wise a_power\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class A_PowerTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transform document representations by element-wise exponentiation\n",
    "        x=(b,c,...,d) -> x'=(b^a, c^a,...,d^a)\n",
    "        If norm='l2' return normalised data.\n",
    "    \"\"\"\n",
    "    def __init__(self, norm='l2', a_power=0.5):\n",
    "        self.norm = norm\n",
    "        self.a_power=a_power\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, copy=True):\n",
    "        X = sp.csr_matrix(X, dtype=np.float64, copy=copy)\n",
    "        X.data **= self.a_power\n",
    "        if self.norm == 'l2':\n",
    "            X = preprocessing.normalize(X, norm=self.norm, copy=False)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.710042432815\n",
      "{'C': 100}\n"
     ]
    }
   ],
   "source": [
    "# Test the application of the tranformer\n",
    "my_transfomer = A_PowerTransformer()\n",
    "Xt_train = my_transfomer.transform(my_representations[2][\"x_train\"])\n",
    "Xt_test  = my_transfomer.transform(my_representations[2][\"x_test\"])\n",
    "clf = grid_search.GridSearchCV(svm.LinearSVC(), param_grid={\"C\":[0.01, 0.1, 1, 10, 100]}, n_jobs=3, scoring='accuracy', refit=True, cv=5)\n",
    "clf.fit(Xt_train, y_train) \n",
    "print metrics.accuracy_score(y_test, clf.predict(Xt_test))\n",
    "print clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "We have investigated basic directions. In particular:\n",
    "\n",
    "- Text vectorization strategies\n",
    "- Tuning using stratified k-fold cross validation\n",
    "- Application of different classifiers using the Sklearn API (fit/transform)\n",
    "- Evaluation using different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.711456859972\n",
      "{'powerTransformer__a_power': 0.6, 'vectorize__ngram_range': (1, 2), 'mySvm__C': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define a sequence of steps...\n",
    "estimators = [('vectorize', CountVectorizer()), (\"powerTransformer\", A_PowerTransformer()),  ('mySvm', svm.LinearSVC())]\n",
    "clf = Pipeline(estimators) # .. group them with a Pipeline ..\n",
    "params = dict(vectorize__ngram_range=[(1,1), (1,2)], powerTransformer__a_power=[0.3, 0.4, 0.5, 0.6], mySvm__C=[0.1, 1, 10, 100]) # .. set look-up parameters..\n",
    "# Hint: we have just defined 32 parameter groups, i.e., 32 x 5 cross-validation problems, which is quite big.\n",
    "tuned_clf = grid_search.GridSearchCV(clf, param_grid=params, n_jobs=3, refit=True, cv=5, ).fit(x_train_raw, y_train) # .. greed search optimize the whole pipeline\n",
    "\n",
    "print  metrics.accuracy_score(y_test, tuned_clf.predict(x_test_raw))\n",
    "print tuned_clf.best_params_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
